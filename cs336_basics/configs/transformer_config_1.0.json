{
    "model": {
        "embedding_size": 512,
        "num_heads": 8,
        "ffn_hidden": 2048,
        "num_layers": 6
    },
    "training": {
        "batch_size": 32,
        "num_epochs": 100,
        "learning_rate": 0.0001
    },
    "dataset": {
        "max_seq_length": 512,
        "vocab_size": 32000
    }
}